{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages, check cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from AutoEncoderClass import *\n",
    "from CAEclass import *\n",
    "from CAE1Dclass import *\n",
    "from VAEclass import *\n",
    "import torchinfo\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get user path to data, create train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test(dataset_path = None, cases = [], channels = []):\n",
    "    data_csv = pd.read_csv(dataset_path)\n",
    "    \n",
    "    \n",
    "    data_pd = pd.DataFrame()\n",
    "    for case_number in cases: #get corresponding case numbers\n",
    "        data_pd = pd.concat([data_pd, data_csv[(data_csv[\"Case\"] == \"case\"+str(case_number))] ])\n",
    "    \n",
    "    data_pd = data_pd[data_pd['Channel'].isin(channels)]  #get corresponding channel numbers\n",
    "    \n",
    "    #train data only needs normal data, validation and test data need normal and abnormal data\n",
    "    data_normal = data_pd[(data_pd[\"norm/ab\"] == \"normal\")]\n",
    "    data_abnormal = data_pd[(data_pd[\"norm/ab\"] == \"abnormal\")]\n",
    "        \n",
    "    train_dataset, interm_dataset  = train_test_split(data_normal, test_size=0.2, shuffle = True)\n",
    "    data_abnormal = pd.concat([data_abnormal, interm_dataset])\n",
    "    validation_dataset, test_dataset= train_test_split(data_abnormal, test_size=0.8, shuffle= True) #only small validation\n",
    "\n",
    "    return shuffle(train_dataset), shuffle(validation_dataset), shuffle(test_dataset)\n",
    "\n",
    "    \n",
    "datapath = r'C:\\Users\\brech\\THESIS_local\\ToyADMOS\\ToycarCSV.csv'\n",
    "train_dataset, validation_dataset, test_dataset = train_val_test(dataset_path = datapath, cases=[1], channels = [\"ch1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Sample Name</th>\n",
       "      <th>Toytype</th>\n",
       "      <th>Case</th>\n",
       "      <th>norm/ab</th>\n",
       "      <th>IND/CNT</th>\n",
       "      <th>Channel</th>\n",
       "      <th>sample_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>010034_ToyCar_case1_normal_IND_ch1_0034.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>010828_ToyCar_case1_normal_IND_ch1_0828.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>011306_ToyCar_case1_normal_IND_ch1_1306.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>011110_ToyCar_case1_normal_IND_ch1_1110.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>010446_ToyCar_case1_normal_IND_ch1_0446.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>010248_ToyCar_case1_normal_IND_ch1_0248.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>010739_ToyCar_case1_normal_IND_ch1_0739.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>010108_ToyCar_case1_normal_IND_ch1_0108.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>010489_ToyCar_case1_normal_IND_ch1_0489.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>010105_ToyCar_case1_normal_IND_ch1_0105.wav</td>\n",
       "      <td>ToyCar</td>\n",
       "      <td>case1</td>\n",
       "      <td>normal</td>\n",
       "      <td>IND</td>\n",
       "      <td>ch1</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Full Sample Name Toytype   Case norm/ab  \\\n",
       "273   010034_ToyCar_case1_normal_IND_ch1_0034.wav  ToyCar  case1  normal   \n",
       "1229  010828_ToyCar_case1_normal_IND_ch1_0828.wav  ToyCar  case1  normal   \n",
       "603   011306_ToyCar_case1_normal_IND_ch1_1306.wav  ToyCar  case1  normal   \n",
       "1435  011110_ToyCar_case1_normal_IND_ch1_1110.wav  ToyCar  case1  normal   \n",
       "949   010446_ToyCar_case1_normal_IND_ch1_0446.wav  ToyCar  case1  normal   \n",
       "...                                           ...     ...    ...     ...   \n",
       "797   010248_ToyCar_case1_normal_IND_ch1_0248.wav  ToyCar  case1  normal   \n",
       "1169  010739_ToyCar_case1_normal_IND_ch1_0739.wav  ToyCar  case1  normal   \n",
       "693   010108_ToyCar_case1_normal_IND_ch1_0108.wav  ToyCar  case1  normal   \n",
       "383   010489_ToyCar_case1_normal_IND_ch1_0489.wav  ToyCar  case1  normal   \n",
       "691   010105_ToyCar_case1_normal_IND_ch1_0105.wav  ToyCar  case1  normal   \n",
       "\n",
       "     IND/CNT Channel  sample_ID  \n",
       "273      IND     ch1         34  \n",
       "1229     IND     ch1        828  \n",
       "603      IND     ch1       1306  \n",
       "1435     IND     ch1       1110  \n",
       "949      IND     ch1        446  \n",
       "...      ...     ...        ...  \n",
       "797      IND     ch1        248  \n",
       "1169     IND     ch1        739  \n",
       "693      IND     ch1        108  \n",
       "383      IND     ch1        489  \n",
       "691      IND     ch1        105  \n",
       "\n",
       "[1080 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets are of the form: Full Sample Name, Toytype,  Case,\tnorm/ab, IND/CNT, Channel, sample_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions \n",
    "def find_path_to_wav(full_sample_name):\n",
    "    for root, dirs, files in os.walk(os.path.dirname(datapath)):\n",
    "        for name in files:\n",
    "            if name == full_sample_name:\n",
    "                path_to_wavFile = os.path.abspath(os.path.join(root, name))\n",
    "                return path_to_wavFile\n",
    "\n",
    "\n",
    "def get_sample_waveform_normalised(full_sample_name, start = 0, stop = 11):\n",
    "    #returns waveform values, cut to seconds going from start to stop\n",
    "    sample_path = find_path_to_wav(full_sample_name)\n",
    "    waveform, sample_rate = librosa.load(sample_path, sr= None)\n",
    "    waveform = waveform[int(start*sample_rate): int(stop*sample_rate)]\n",
    "        \n",
    "    return librosa.util.normalize(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wav = train_dataset[\"Full Sample Name\"].values\n",
    "X_test_wav = test_dataset[\"Full Sample Name\"].values\n",
    "X_valid_wav = validation_dataset[\"Full Sample Name\"].values\n",
    "\n",
    "#when using the linear AE\n",
    "# batch_train = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_train_wav]) \n",
    "# batch_test = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_test_wav])\n",
    "# batch_val = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_valid_wav])\n",
    "\n",
    "#when using the CAE\n",
    "batch_train = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_train_wav]) # hier wss nog resizen voor CAE\n",
    "batch_test = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_test_wav])\n",
    "batch_val = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_valid_wav])\n",
    "\n",
    "\n",
    "#when using the CAE1D\n",
    "# batch_train_reshaped =  np.reshape(batch_train,(-1,1,8000))\n",
    "# batch_test_reshaped =  np.reshape(batch_test,(-1,1,8000))\n",
    "# batch_val_reshaped =  np.reshape(batch_val,(-1,1,8000))\n",
    "\n",
    "#when using the CAE\n",
    "batch_train_reshaped =  np.reshape(batch_train,(len(batch_train),1,8000,1))\n",
    "batch_test_reshaped =  np.reshape(batch_test,(len(batch_test),1,8000,1))\n",
    "batch_val_reshaped =  np.reshape(batch_val,(len(batch_val),1,8000,1))\n",
    "\n",
    "#when using the linear AE\n",
    "# X_train = DataLoader(batch_train, batch_size = 64, shuffle = False)\n",
    "# X_test = DataLoader(batch_test, batch_size = 64, shuffle = False)\n",
    "# X_val = DataLoader(batch_val, batch_size = 64, shuffle = False)\n",
    "\n",
    "X_train = DataLoader(batch_train_reshaped, batch_size = 32, shuffle = False)  #batch_train_reshaped\n",
    "X_test = DataLoader(batch_test_reshaped, batch_size = 32, shuffle = False)\n",
    "X_val = DataLoader(batch_val_reshaped, batch_size = 32, shuffle = False)\n",
    "\n",
    "Y_train = train_dataset[\"norm/ab\"]\n",
    "Y_train = np.array([ 1 if i == \"normal\" else -1 for i in Y_train ]).reshape(-1, 1) #rewrite to -1 and 1 instead of strings 'normal'/'abnormal'\n",
    "\n",
    "Y_val = validation_dataset[\"norm/ab\"]\n",
    "Y_val = np.array([ 1 if i == \"normal\" else -1 for i in Y_val ]).reshape(-1, 1)\n",
    "\n",
    "Y_test = test_dataset[\"norm/ab\"]\n",
    "Y_test = np.array([ 1 if i == \"normal\" else -1 for i in Y_test ]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#AFTER THIS POINT NO SHUFFLING IS DONE, SO DATA FROM XTRAIN LINES UP YTRAIN, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example, batch_test is (1709,16000)\n",
    "with batch size of 32, this gives 53.4 (so 54) arrays, each with 32 samples \n",
    "\n",
    "so 1 batch: 32 samples, size (32, 16000)\n",
    "==> 54 batches\n",
    "\n",
    "idea is to feed batch per batch to the neural net\n",
    "\n",
    "\n",
    "for batch_train (4320,16000) this would give 135 batches (each with 32 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set autoencoder parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the model by choosing which cell to run\n",
    "model = AutoEncoder(8000).to(device=device) #assume 0.5 sec of waveform\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1, 8000, 1)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE1D().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1,8000)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note VAE needs as losses both the training_loss and KL loss(how close to a normal distribution the values are): https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "model = LinearVAE(8000).to(device=device)\n",
    "torchinfo.summary(model) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvolutedVAE                            [1, 1, 8000, 1]           --\n",
       "â”œâ”€Sequential: 1-1                        [1, 32, 4000, 1]          --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [1, 32, 8000, 1]          128\n",
       "â”‚    â””â”€Tanh: 2-2                         [1, 32, 8000, 1]          --\n",
       "â”‚    â””â”€MaxPool2d: 2-3                    [1, 32, 4000, 1]          --\n",
       "â”œâ”€Sequential: 1-2                        [1, 64, 2000, 1]          --\n",
       "â”‚    â””â”€Conv2d: 2-4                       [1, 64, 4000, 1]          6,208\n",
       "â”‚    â””â”€Tanh: 2-5                         [1, 64, 4000, 1]          --\n",
       "â”‚    â””â”€MaxPool2d: 2-6                    [1, 64, 2000, 1]          --\n",
       "â”œâ”€Sequential: 1-3                        [1, 128, 1000, 1]         --\n",
       "â”‚    â””â”€Conv2d: 2-7                       [1, 128, 2000, 1]         24,704\n",
       "â”‚    â””â”€Tanh: 2-8                         [1, 128, 2000, 1]         --\n",
       "â”‚    â””â”€MaxPool2d: 2-9                    [1, 128, 1000, 1]         --\n",
       "â”œâ”€Sequential: 1-4                        [1, 256, 500, 1]          --\n",
       "â”‚    â””â”€Conv2d: 2-10                      [1, 256, 1000, 1]         98,560\n",
       "â”‚    â””â”€Tanh: 2-11                        [1, 256, 1000, 1]         --\n",
       "â”‚    â””â”€MaxPool2d: 2-12                   [1, 256, 500, 1]          --\n",
       "â”œâ”€Sequential: 1-5                        [1, 512, 250, 1]          --\n",
       "â”‚    â””â”€Conv2d: 2-13                      [1, 512, 500, 1]          393,728\n",
       "â”‚    â””â”€Tanh: 2-14                        [1, 512, 500, 1]          --\n",
       "â”‚    â””â”€MaxPool2d: 2-15                   [1, 512, 250, 1]          --\n",
       "â”œâ”€Linear: 1-6                            [1, 256]                  32,768,256\n",
       "â”œâ”€Linear: 1-7                            [1, 256]                  32,768,256\n",
       "â”œâ”€Sequential: 1-8                        [1, 128000]               --\n",
       "â”‚    â””â”€Linear: 2-16                      [1, 128000]               32,896,000\n",
       "â”‚    â””â”€Tanh: 2-17                        [1, 128000]               --\n",
       "â”œâ”€Sequential: 1-9                        [1, 256, 500, 1]          --\n",
       "â”‚    â””â”€ConvTranspose2d: 2-18             [1, 256, 500, 1]          262,400\n",
       "â”‚    â””â”€Tanh: 2-19                        [1, 256, 500, 1]          --\n",
       "â”œâ”€Sequential: 1-10                       [1, 128, 1000, 1]         --\n",
       "â”‚    â””â”€ConvTranspose2d: 2-20             [1, 128, 1000, 1]         65,664\n",
       "â”‚    â””â”€Tanh: 2-21                        [1, 128, 1000, 1]         --\n",
       "â”œâ”€Sequential: 1-11                       [1, 64, 2000, 1]          --\n",
       "â”‚    â””â”€ConvTranspose2d: 2-22             [1, 64, 2000, 1]          16,448\n",
       "â”‚    â””â”€Tanh: 2-23                        [1, 64, 2000, 1]          --\n",
       "â”œâ”€Sequential: 1-12                       [1, 32, 4000, 1]          --\n",
       "â”‚    â””â”€ConvTranspose2d: 2-24             [1, 32, 4000, 1]          4,128\n",
       "â”‚    â””â”€Tanh: 2-25                        [1, 32, 4000, 1]          --\n",
       "â”œâ”€Sequential: 1-13                       [1, 1, 8000, 1]           --\n",
       "â”‚    â””â”€ConvTranspose2d: 2-26             [1, 1, 8000, 1]           65\n",
       "â”‚    â””â”€Tanh: 2-27                        [1, 1, 8000, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 99,304,545\n",
       "Trainable params: 99,304,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 715.91\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 15.43\n",
       "Params size (MB): 397.22\n",
       "Estimated Total Size (MB): 412.68\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutedVAE().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1, 8000, 1)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = nn.MSELoss()    #?nn.L1Loss() best type of loss for sound?, MSE loss seems to result in lower loss\n",
    "learning_rate = 0.0001  #0.0001 seems best so far\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [16:20<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "avg_val_losses = []\n",
    "\n",
    "\n",
    "def train(epochs, model, model_loss):\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        \n",
    "        for batch_idx, data in enumerate(X_train):\n",
    "            \n",
    "            model.train(True)\n",
    "            # Zero your gradients for every batch!\n",
    "            model.zero_grad()\n",
    "            \n",
    "            #for param in model.parameters(): #instead of model.zero_grad: https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#:~:text=implement%20this%20optimization.-,Use%20parameter.grad,-%3D%20None%20instead%20of\n",
    "            #    param.grad = None\n",
    "            \n",
    "            # Make predictions for this batch\n",
    "            data_gpu = data.to(device= device)\n",
    "            \n",
    "            outputs = model(data_gpu)\n",
    "    \n",
    "            # Compute the loss and its gradients\n",
    "            loss = model_loss(outputs, data_gpu)  +model.KL_Loss #extra term for VAE\n",
    "           \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            losses.append(loss.item())\n",
    "            #del loss \n",
    "            #del data #free memory\n",
    "            #del outputs\n",
    "            \n",
    "            model.train(False)\n",
    "\n",
    "        \n",
    "        #hier validation data gebruiken, gets run once per epoch\n",
    "        #get average loss value of the validation data\n",
    "        running_val_loss = []\n",
    "        for val_data in X_val:\n",
    "            val_data_gpu = val_data.to(device=device)\n",
    "            val_outputs = model(val_data_gpu)\n",
    "            val_loss = model_loss(val_outputs, val_data_gpu)\n",
    "            \n",
    "            running_val_loss.append(val_loss.item())\n",
    "\n",
    "        avg_val_losses.append(np.average(running_val_loss))\n",
    "\n",
    "train(model=model, epochs=epochs, model_loss=model_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(avg_val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of how good the model did, compare file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "lines = [now, model, model_loss,learning_rate,epochs,optimizer,losses[-100:], avg_val_losses ]\n",
    "with open('All results.txt', 'a') as f:\n",
    "    for line in lines:\n",
    "        f.write(str(line))\n",
    "        f.write('\\n')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model on the test data and get a score(normal_score/anomaly_score) to hopefully see a difference:\\\n",
    "https://neptune.ai/blog/pytorch-loss-functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(dataset, scoring_function): \n",
    "    scores_normal = [] #scores of each waveform in the test datase\n",
    "    scores_abnormal = []\n",
    "    \n",
    "    for line_of_data in dataset.iloc():\n",
    "        waveform = np.array(get_sample_waveform_normalised(line_of_data[\"Full Sample Name\"], 4, 4.5))\n",
    "        waveform = np.reshape(waveform,(-1, 1,8000,1))\n",
    "        waveform_gpu = torch.FloatTensor(waveform).to(device=device)\n",
    "\n",
    "        predicted_waveform = model(waveform_gpu)\n",
    "        error = scoring_function(predicted_waveform,waveform_gpu)   +model.KL_Loss  #add term form VAE\n",
    "        \n",
    "        if line_of_data[\"norm/ab\"] == \"normal\":\n",
    "            scores_normal.append(error.detach().cpu().numpy().item()) \n",
    "        \n",
    "        if line_of_data[\"norm/ab\"] == \"abnormal\":\n",
    "            scores_abnormal.append(error.detach().cpu().numpy().item()) \n",
    "   \n",
    "    return scores_normal, scores_abnormal\n",
    "\n",
    "MSE_scores_normal, MSE_scores_abnormal = score(test_dataset, scoring_function = nn.MSELoss())\n",
    "L1_scores_normal, L1_scores_abnormal = score(test_dataset, scoring_function = nn.L1Loss())\n",
    "CEL_scores_normal, CEL_scores_abnormal =score(test_dataset, scoring_function =nn.CrossEntropyLoss()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,13))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(range(len(MSE_scores_normal)), MSE_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(MSE_scores_abnormal)), MSE_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"MSE score \")\n",
    "\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(range(len(L1_scores_normal)), L1_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(L1_scores_abnormal)), L1_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"L1 score \")\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(range(len(CEL_scores_normal)), CEL_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(CEL_scores_abnormal)), CEL_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"CrossEntropy score \")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#RESCALE DATA! met standardscaler\n",
    "L1_scores_normal = np.array(L1_scores_normal).reshape(-1, 1)\n",
    "L1_scores_abnormal = np.array(L1_scores_abnormal).reshape(-1, 1)\n",
    "\n",
    "scaler_normal = StandardScaler() #necessary?\n",
    "scaler_normal.fit_transform(L1_scores_normal)\n",
    "\n",
    "scaler_abnormal = StandardScaler()\n",
    "scaler_abnormal.fit_transform(L1_scores_abnormal)\n",
    "\n",
    "L1_all_scores = np.append(L1_scores_abnormal, L1_scores_normal).reshape(-1, 1) # first abnormal(-1), then normal(1) # test scores\n",
    "L1_all_results = np.ravel(np.concatenate((np.ones_like(L1_scores_abnormal)*(-1), np.ones_like(L1_scores_normal)), axis=0)) #true result\n",
    "\n",
    "# confusion matrix and ROC curve\n",
    "fpr, tpr, _ = roc_curve(L1_all_results,L1_all_scores )  #y_true, y_score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=3, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=3, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "underneath is just test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a best boundary between noral and abnormal scores\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "#RESCALE DATA! met standardscaler\n",
    "L1_scores_normal, L1_scores_abnormal = np.array(L1_scores_normal), np.array(L1_scores_abnormal)\n",
    "L1_scores_normal, L1_scores_abnormal = L1_scores_normal.reshape(-1, 1), L1_scores_abnormal.reshape(-1,1)\n",
    "\n",
    "scaler_normal = StandardScaler()\n",
    "scaler_normal.fit_transform(L1_scores_normal)\n",
    "\n",
    "scaler_abnormal = StandardScaler()\n",
    "scaler_abnormal.fit_transform(L1_scores_abnormal)\n",
    "\n",
    "L1_all_scores = np.append(L1_scores_abnormal, L1_scores_normal).reshape(-1, 1) # first abnormal(-1), then normal(1)\n",
    "L1_all_results = np.ravel(np.concatenate((np.ones_like(L1_scores_abnormal)*(-1), np.ones_like(L1_scores_normal)), axis=0))\n",
    "\n",
    "################################################################\n",
    "svc = svm.SVC(kernel= 'rbf', probability = True) # Kernel\n",
    "svc.fit(L1_all_scores, L1_all_results)\n",
    "result = svc.predict(L1_all_scores)\n",
    "\n",
    "result_proba = svc.predict_proba(L1_all_scores)[:,1] #predicted chance of being 1 (=Normal)\n",
    "\n",
    "\n",
    "#get correct percentage(True positive and true negative)\n",
    "\n",
    "(L1_all_results == result).sum()/float(len(result))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the ROC and AUC plots\n",
    "ROC_AUC curve of andere general methode om het model te testen\\\n",
    "andere methode PR_AUC\n",
    "+confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(L1_all_results, result, labels = svc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = svc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve, roc_auc_score, RocCurveDisplay, roc_curve\n",
    "print(roc_auc_score(L1_all_results,result))\n",
    "\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(L1_all_results, result_proba)\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic-svm')\n",
    "plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "\n",
    "X = np.asarray([[1, 1], [2, 2], [3, 3], [4, 4], [1.2, 1.2], [3.2, 3.2],[1.46, 1.46],[1.25, 1.25],[3.26, 3.26],[2.23, 2.23]]) #The Y Coordinates here are meaningless\n",
    "Labels = [1, 2, 1,1,1,2, 2, 1, 1,3]\n",
    "\n",
    "#Classifier\n",
    "svc = svm.SVC(kernel='rbf', C = 100).fit(X, Labels)\n",
    "#Meshgrid for Contour Plot\n",
    "x_min, x_max = np.min(X) - 1, np.max(X) + 1\n",
    "y_min, y_max = 0, 5\n",
    "h = .02  # step size in the mesh    \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                 np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "# Draw Contour Plot\n",
    "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "# Plot training points\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.xlabel('Signal')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.yticks(()); #Y value is meaningless in this data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "820d507683270d6b65f843676203e5ed0fadcdee93b1b6d49e394f227c8eaef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
