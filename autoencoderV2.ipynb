{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages, check cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from AutoEncoderClass import *\n",
    "from CAEclass import *\n",
    "from CAE1Dclass import *\n",
    "from VAEclass import *\n",
    "import torchinfo\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get user path to data, create train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test(dataset_path = None, cases = [], channels = []):\n",
    "    data_csv = pd.read_csv(dataset_path)\n",
    "    \n",
    "    \n",
    "    data_pd = pd.DataFrame()\n",
    "    for case_number in cases: #get corresponding case numbers\n",
    "        data_pd = pd.concat([data_pd, data_csv[(data_csv[\"Case\"] == \"case\"+str(case_number))] ])\n",
    "    \n",
    "    data_pd = data_pd[data_pd['Channel'].isin(channels)]  #get corresponding channel numbers\n",
    "    \n",
    "    #train data only needs normal data, validation and test data need normal and abnormal data\n",
    "    data_normal = data_pd[(data_pd[\"norm/ab\"] == \"normal\")]\n",
    "    data_abnormal = data_pd[(data_pd[\"norm/ab\"] == \"abnormal\")]\n",
    "        \n",
    "    train_dataset, interm_dataset  = train_test_split(data_normal, test_size=0.2, shuffle = True)\n",
    "    data_abnormal = pd.concat([data_abnormal, interm_dataset])\n",
    "    validation_dataset, test_dataset= train_test_split(data_abnormal, test_size=0.8, shuffle= True) #only small validation\n",
    "\n",
    "    return shuffle(train_dataset), shuffle(validation_dataset), shuffle(test_dataset)\n",
    "\n",
    "    \n",
    "datapath = r'C:\\Users\\brech\\THESIS_local\\ToyADMOS\\ToycarCSV.csv'\n",
    "train_dataset, validation_dataset, test_dataset = train_val_test(dataset_path = datapath, cases=[4], channels = [\"ch1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets are of the form: Full Sample Name, Toytype,  Case,\tnorm/ab, IND/CNT, Channel, sample_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions \n",
    "def find_path_to_wav(full_sample_name):\n",
    "    for root, dirs, files in os.walk(os.path.dirname(datapath)):\n",
    "        for name in files:\n",
    "            if name == full_sample_name:\n",
    "                path_to_wavFile = os.path.abspath(os.path.join(root, name))\n",
    "                return path_to_wavFile\n",
    "\n",
    "\n",
    "def get_sample_waveform_normalised(full_sample_name, start = 0, stop = 11):\n",
    "    #returns waveform values, cut to seconds going from start to stop\n",
    "    sample_path = find_path_to_wav(full_sample_name)\n",
    "    waveform, sample_rate = librosa.load(sample_path, sr= None)\n",
    "    waveform = waveform[int(start*sample_rate): int(stop*sample_rate)]\n",
    "        \n",
    "    return librosa.util.normalize(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wav = train_dataset[\"Full Sample Name\"].values\n",
    "X_test_wav = test_dataset[\"Full Sample Name\"].values\n",
    "X_valid_wav = validation_dataset[\"Full Sample Name\"].values\n",
    "\n",
    "#when using the linear AE\n",
    "batch_train = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_train_wav]) \n",
    "batch_test = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_test_wav])\n",
    "batch_val = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_valid_wav])\n",
    "\n",
    "#when using the CAE\n",
    "# batch_train = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_train_wav]) # hier wss nog resizen voor CAE\n",
    "# batch_test = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_test_wav])\n",
    "# batch_val = np.array([get_sample_waveform_normalised(elem,4,4.5) for elem in X_valid_wav])\n",
    "\n",
    "\n",
    "#when using the CAE1D\n",
    "# batch_train_reshaped =  np.reshape(batch_train,(-1,1,8000))\n",
    "# batch_test_reshaped =  np.reshape(batch_test,(-1,1,8000))\n",
    "# batch_val_reshaped =  np.reshape(batch_val,(-1,1,8000))\n",
    "\n",
    "#when using the CAE\n",
    "# batch_train_reshaped =  np.reshape(batch_train,(len(batch_train),1,8000,1))\n",
    "# batch_test_reshaped =  np.reshape(batch_test,(len(batch_test),1,8000,1))\n",
    "# batch_val_reshaped =  np.reshape(batch_val,(len(batch_val),1,8000,1))\n",
    "\n",
    "#when using the linear AE\n",
    "X_train = DataLoader(batch_train, batch_size = 64, shuffle = False)\n",
    "X_test = DataLoader(batch_test, batch_size = 64, shuffle = False)\n",
    "X_val = DataLoader(batch_val, batch_size = 64, shuffle = False)\n",
    "\n",
    "# X_train = DataLoader(batch_train_reshaped, batch_size = 64, shuffle = False)  #batch_train_reshaped\n",
    "# X_test = DataLoader(batch_test_reshaped, batch_size = 64, shuffle = False)\n",
    "# X_val = DataLoader(batch_val_reshaped, batch_size = 64, shuffle = False)\n",
    "\n",
    "Y_train = train_dataset[\"norm/ab\"]\n",
    "Y_train = np.array([ 1 if i == \"normal\" else -1 for i in Y_train ]).reshape(-1, 1) #rewrite to -1 and 1 instead of strings 'normal'/'abnormal'\n",
    "\n",
    "Y_val = validation_dataset[\"norm/ab\"]\n",
    "Y_val = np.array([ 1 if i == \"normal\" else -1 for i in Y_val ]).reshape(-1, 1)\n",
    "\n",
    "Y_test = test_dataset[\"norm/ab\"]\n",
    "Y_test = np.array([ 1 if i == \"normal\" else -1 for i in Y_test ]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#AFTER THIS POINT NO SHUFFLING IS DONE, SO DATA FROM XTRAIN LINES UP YTRAIN, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example, batch_test is (1709,16000)\n",
    "with batch size of 32, this gives 53.4 (so 54) arrays, each with 32 samples \n",
    "\n",
    "so 1 batch: 32 samples, size (32, 16000)\n",
    "==> 54 batches\n",
    "\n",
    "idea is to feed batch per batch to the neural net\n",
    "\n",
    "\n",
    "for batch_train (4320,16000) this would give 135 batches (each with 32 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set autoencoder parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the model by choosing which cell to run\n",
    "model = AutoEncoder(8000).to(device=device) #assume 0.5 sec of waveform\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1, 8000, 1)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE1D().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1,8000)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note VAE needs as losses both the training_loss and KL loss(how close to a normal distribution the values are): https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "model = LinearVAE(8000).to(device=device)\n",
    "torchinfo.summary(model) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvolutedVAE                            [1, 1, 8000, 1]           --\n",
       "├─Sequential: 1-1                        [1, 32, 4000, 1]          --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 8000, 1]          128\n",
       "│    └─Tanh: 2-2                         [1, 32, 8000, 1]          --\n",
       "│    └─MaxPool2d: 2-3                    [1, 32, 4000, 1]          --\n",
       "├─Sequential: 1-2                        [1, 64, 2000, 1]          --\n",
       "│    └─Conv2d: 2-4                       [1, 64, 4000, 1]          6,208\n",
       "│    └─Tanh: 2-5                         [1, 64, 4000, 1]          --\n",
       "│    └─MaxPool2d: 2-6                    [1, 64, 2000, 1]          --\n",
       "├─Sequential: 1-3                        [1, 128, 1000, 1]         --\n",
       "│    └─Conv2d: 2-7                       [1, 128, 2000, 1]         24,704\n",
       "│    └─Tanh: 2-8                         [1, 128, 2000, 1]         --\n",
       "│    └─MaxPool2d: 2-9                    [1, 128, 1000, 1]         --\n",
       "├─Sequential: 1-4                        [1, 256, 500, 1]          --\n",
       "│    └─Conv2d: 2-10                      [1, 256, 1000, 1]         98,560\n",
       "│    └─Tanh: 2-11                        [1, 256, 1000, 1]         --\n",
       "│    └─MaxPool2d: 2-12                   [1, 256, 500, 1]          --\n",
       "├─Sequential: 1-5                        [1, 512, 250, 1]          --\n",
       "│    └─Conv2d: 2-13                      [1, 512, 500, 1]          393,728\n",
       "│    └─Tanh: 2-14                        [1, 512, 500, 1]          --\n",
       "│    └─MaxPool2d: 2-15                   [1, 512, 250, 1]          --\n",
       "├─Linear: 1-6                            [1, 256]                  32,768,256\n",
       "├─Linear: 1-7                            [1, 256]                  32,768,256\n",
       "├─Sequential: 1-8                        [1, 128000]               --\n",
       "│    └─Linear: 2-16                      [1, 128000]               32,896,000\n",
       "│    └─Tanh: 2-17                        [1, 128000]               --\n",
       "├─Sequential: 1-9                        [1, 256, 500, 1]          --\n",
       "│    └─ConvTranspose2d: 2-18             [1, 256, 500, 1]          262,400\n",
       "│    └─Tanh: 2-19                        [1, 256, 500, 1]          --\n",
       "├─Sequential: 1-10                       [1, 128, 1000, 1]         --\n",
       "│    └─ConvTranspose2d: 2-20             [1, 128, 1000, 1]         65,664\n",
       "│    └─Tanh: 2-21                        [1, 128, 1000, 1]         --\n",
       "├─Sequential: 1-11                       [1, 64, 2000, 1]          --\n",
       "│    └─ConvTranspose2d: 2-22             [1, 64, 2000, 1]          16,448\n",
       "│    └─Tanh: 2-23                        [1, 64, 2000, 1]          --\n",
       "├─Sequential: 1-12                       [1, 32, 4000, 1]          --\n",
       "│    └─ConvTranspose2d: 2-24             [1, 32, 4000, 1]          4,128\n",
       "│    └─Tanh: 2-25                        [1, 32, 4000, 1]          --\n",
       "├─Sequential: 1-13                       [1, 1, 8000, 1]           --\n",
       "│    └─ConvTranspose2d: 2-26             [1, 1, 8000, 1]           65\n",
       "│    └─Tanh: 2-27                        [1, 1, 8000, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 99,304,545\n",
       "Trainable params: 99,304,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 715.91\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 15.43\n",
       "Params size (MB): 397.22\n",
       "Estimated Total Size (MB): 412.68\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutedVAE().to(device=device)\n",
    "torchinfo.summary(model, input_size=(1,1, 8000, 1)) #batch_size, channel, rows,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = nn.MSELoss()    #?nn.L1Loss() best type of loss for sound?, MSE loss seems to result in lower loss\n",
    "learning_rate = 0.0001  #0.0001 seems best so far\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "losses = []\n",
    "avg_val_losses = []\n",
    "\n",
    "\n",
    "def train(epochs, model, model_loss):\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        \n",
    "        for batch_idx, data in enumerate(X_train):\n",
    "            \n",
    "            model.train(True)\n",
    "            # Zero your gradients for every batch!\n",
    "            model.zero_grad()\n",
    "            \n",
    "            #for param in model.parameters(): #instead of model.zero_grad: https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#:~:text=implement%20this%20optimization.-,Use%20parameter.grad,-%3D%20None%20instead%20of\n",
    "            #    param.grad = None\n",
    "            \n",
    "            # Make predictions for this batch\n",
    "            data_gpu = data.to(device= device)\n",
    "            \n",
    "            outputs = model(data_gpu)\n",
    "    \n",
    "            # Compute the loss and its gradients\n",
    "            loss = model_loss(outputs, data_gpu)  #+model.KL_Loss #extra term for VAE\n",
    "           \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            losses.append(loss.item())\n",
    "            #del loss \n",
    "            #del data #free memory\n",
    "            #del outputs\n",
    "            \n",
    "            model.train(False)\n",
    "\n",
    "        \n",
    "        #hier validation data gebruiken, gets run once per epoch\n",
    "        #get average loss value of the validation data\n",
    "        running_val_loss = []\n",
    "        for val_data in X_val:\n",
    "            val_data_gpu = val_data.to(device=device)\n",
    "            val_outputs = model(val_data_gpu)\n",
    "            val_loss = model_loss(val_outputs, val_data_gpu)\n",
    "            \n",
    "            running_val_loss.append(val_loss.item())\n",
    "\n",
    "        avg_val_losses.append(np.average(running_val_loss))\n",
    "\n",
    "train(model=model, epochs=epochs, model_loss=model_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(avg_val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of how good the model did, compare file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "lines = [now, model, model_loss,learning_rate,epochs,optimizer,losses[-100:], avg_val_losses ]\n",
    "with open('All results.txt', 'a') as f:\n",
    "    for line in lines:\n",
    "        f.write(str(line))\n",
    "        f.write('\\n')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model on the test data and get a score(normal_score/anomaly_score) to hopefully see a difference:\\\n",
    "https://neptune.ai/blog/pytorch-loss-functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(dataset, scoring_function): \n",
    "    scores_normal = [] #scores of each waveform in the test datase\n",
    "    scores_abnormal = []\n",
    "    \n",
    "    for line_of_data in dataset.iloc():\n",
    "        waveform = np.array(get_sample_waveform_normalised(line_of_data[\"Full Sample Name\"], 4, 4.5))\n",
    "        #waveform = np.reshape(waveform,(-1, 1,8000,1))\n",
    "        waveform_gpu = torch.FloatTensor(waveform).to(device=device)\n",
    "\n",
    "        predicted_waveform = model(waveform_gpu)\n",
    "        error = scoring_function(predicted_waveform,waveform_gpu)  # +model.KL_Loss  #add term form VAE\n",
    "        \n",
    "        if line_of_data[\"norm/ab\"] == \"normal\":\n",
    "            scores_normal.append(error.detach().cpu().numpy().item()) \n",
    "        \n",
    "        if line_of_data[\"norm/ab\"] == \"abnormal\":\n",
    "            scores_abnormal.append(error.detach().cpu().numpy().item()) \n",
    "   \n",
    "    return scores_normal, scores_abnormal\n",
    "\n",
    "MSE_scores_normal, MSE_scores_abnormal = score(test_dataset, scoring_function = nn.MSELoss())\n",
    "L1_scores_normal, L1_scores_abnormal = score(test_dataset, scoring_function = nn.L1Loss())\n",
    "CEL_scores_normal, CEL_scores_abnormal =score(test_dataset, scoring_function =nn.CrossEntropyLoss()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,13))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(range(len(MSE_scores_normal)), MSE_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(MSE_scores_abnormal)), MSE_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"MSE score \")\n",
    "\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(range(len(L1_scores_normal)), L1_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(L1_scores_abnormal)), L1_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"L1 score \")\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(range(len(CEL_scores_normal)), CEL_scores_normal, 'bx',linewidth=1, markersize=2) \n",
    "plt.plot(range(len(CEL_scores_abnormal)), CEL_scores_abnormal, 'rx', linewidth=1, markersize=2 ) \n",
    "plt.title(\"CrossEntropy score \")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#RESCALE DATA! met standardscaler\n",
    "L1_scores_normal = np.array(L1_scores_normal).reshape(-1, 1)\n",
    "L1_scores_abnormal = np.array(L1_scores_abnormal).reshape(-1, 1)\n",
    "\n",
    "scaler_normal = StandardScaler() #necessary?\n",
    "scaler_normal.fit_transform(L1_scores_normal)\n",
    "\n",
    "scaler_abnormal = StandardScaler()\n",
    "scaler_abnormal.fit_transform(L1_scores_abnormal)\n",
    "\n",
    "L1_all_scores = np.append(L1_scores_abnormal, L1_scores_normal).reshape(-1, 1) # first abnormal(-1), then normal(1) # test scores\n",
    "L1_all_results = np.ravel(np.concatenate((np.ones_like(L1_scores_abnormal)*(-1), np.ones_like(L1_scores_normal)), axis=0)) #true result\n",
    "\n",
    "# confusion matrix and ROC curve\n",
    "fpr, tpr, _ = roc_curve(L1_all_results,L1_all_scores )  #y_true, y_score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=3, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=3, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "underneath is just test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a best boundary between noral and abnormal scores\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "#RESCALE DATA! met standardscaler\n",
    "L1_scores_normal, L1_scores_abnormal = np.array(L1_scores_normal), np.array(L1_scores_abnormal)\n",
    "L1_scores_normal, L1_scores_abnormal = L1_scores_normal.reshape(-1, 1), L1_scores_abnormal.reshape(-1,1)\n",
    "\n",
    "scaler_normal = StandardScaler()\n",
    "scaler_normal.fit_transform(L1_scores_normal)\n",
    "\n",
    "scaler_abnormal = StandardScaler()\n",
    "scaler_abnormal.fit_transform(L1_scores_abnormal)\n",
    "\n",
    "L1_all_scores = np.append(L1_scores_abnormal, L1_scores_normal).reshape(-1, 1) # first abnormal(-1), then normal(1)\n",
    "L1_all_results = np.ravel(np.concatenate((np.ones_like(L1_scores_abnormal)*(-1), np.ones_like(L1_scores_normal)), axis=0))\n",
    "\n",
    "################################################################\n",
    "svc = svm.SVC(kernel= 'rbf', probability = True) # Kernel\n",
    "svc.fit(L1_all_scores, L1_all_results)\n",
    "result = svc.predict(L1_all_scores)\n",
    "\n",
    "result_proba = svc.predict_proba(L1_all_scores)[:,1] #predicted chance of being 1 (=Normal)\n",
    "\n",
    "\n",
    "#get correct percentage(True positive and true negative)\n",
    "\n",
    "(L1_all_results == result).sum()/float(len(result))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the ROC and AUC plots\n",
    "ROC_AUC curve of andere general methode om het model te testen\\\n",
    "andere methode PR_AUC\n",
    "+confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(L1_all_results, result, labels = svc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = svc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve, roc_auc_score, RocCurveDisplay, roc_curve\n",
    "print(roc_auc_score(L1_all_results,result))\n",
    "\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(L1_all_results, result_proba)\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic-svm')\n",
    "plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "\n",
    "X = np.asarray([[1, 1], [2, 2], [3, 3], [4, 4], [1.2, 1.2], [3.2, 3.2],[1.46, 1.46],[1.25, 1.25],[3.26, 3.26],[2.23, 2.23]]) #The Y Coordinates here are meaningless\n",
    "Labels = [1, 2, 1,1,1,2, 2, 1, 1,3]\n",
    "\n",
    "#Classifier\n",
    "svc = svm.SVC(kernel='rbf', C = 100).fit(X, Labels)\n",
    "#Meshgrid for Contour Plot\n",
    "x_min, x_max = np.min(X) - 1, np.max(X) + 1\n",
    "y_min, y_max = 0, 5\n",
    "h = .02  # step size in the mesh    \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                 np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "# Draw Contour Plot\n",
    "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "# Plot training points\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.xlabel('Signal')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.yticks(()); #Y value is meaningless in this data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "820d507683270d6b65f843676203e5ed0fadcdee93b1b6d49e394f227c8eaef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
