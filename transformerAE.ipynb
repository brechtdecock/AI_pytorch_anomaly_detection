{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from transformerclass import *\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    \"\"\"Loads a dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(dataset_path)\n",
    "\n",
    "def filter_dataset_by_cases_and_channels(dataset, cases, channels):\n",
    "    \"\"\"Filters a dataset to keep only the rows that correspond to the specified cases and channels.\"\"\"\n",
    "    selected_rows = pd.DataFrame()\n",
    "    for case_number in cases:\n",
    "        rows_for_case = dataset[dataset['Case'] == f'case{case_number}']\n",
    "        selected_rows = pd.concat([selected_rows, rows_for_case])\n",
    "    selected_rows = selected_rows[selected_rows['Channel'].isin(channels)]\n",
    "    return selected_rows\n",
    "\n",
    "def split_dataset_for_train_val_test(data_pd):\n",
    "    \"\"\"Splits a dataset into three parts: train, validation, and test.\"\"\"\n",
    "    normal_data = data_pd[data_pd['norm/ab'] == 'normal']\n",
    "    abnormal_data = data_pd[data_pd['norm/ab'] == 'abnormal']\n",
    "    \n",
    "    # We only need normal data for training, but validation and test need both normal and abnormal data.\n",
    "    train_data, intermediate_data = train_test_split(normal_data, test_size=0.2, shuffle=True)\n",
    "    validation_data, test_data = train_test_split(pd.concat([abnormal_data, intermediate_data]), test_size=0.8, shuffle=True)\n",
    "\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "def train_val_test(dataset_path=None, cases=[], channels=[]):\n",
    "    \"\"\"Loads a dataset, filters it, and splits it for training, validation, and test.\"\"\"\n",
    "    dataset = load_dataset(dataset_path)\n",
    "    filtered_dataset = filter_dataset_by_cases_and_channels(dataset, cases, channels)\n",
    "    train_data, validation_data, test_data = split_dataset_for_train_val_test(filtered_dataset)\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "\n",
    "datapath = r'C:\\Users\\brech\\THESIS_local\\ToyADMOS\\ToycarCSV.csv'\n",
    "cases = [1]\n",
    "channels = ['ch1']\n",
    "train_data, validation_data, test_data = train_val_test(dataset_path=datapath, cases=cases, channels=channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (1080, 7) \n",
      " validation shape:  (106, 7) \n",
      " test_dataset:  (428, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", train_data.shape, \"\\n\", \"validation shape: \", validation_data.shape, \"\\n\", \"test_dataset: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions \n",
    "def find_path_to_wav(full_sample_name):\n",
    "    for root, dirs, files in os.walk(os.path.dirname(datapath)):\n",
    "        for name in files:\n",
    "            if name == full_sample_name:\n",
    "                path_to_wavFile = os.path.abspath(os.path.join(root, name))\n",
    "                return path_to_wavFile\n",
    "\n",
    "\n",
    "def get_sample_waveform_normalised(full_sample_name, start = 0, stop = 11):\n",
    "    #returns waveform values, cut to seconds going from start to stop\n",
    "    sample_path = find_path_to_wav(full_sample_name)\n",
    "    waveform, sample_rate = librosa.load(sample_path, sr= None)\n",
    "    waveform = waveform[int(start*sample_rate): int(stop*sample_rate)]\n",
    "        \n",
    "    return librosa.util.normalize(waveform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
